{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabajo Final CNN - Style Transfer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCY6UbkkI9_N"
      },
      "source": [
        "# Style Transfer\n",
        "\n",
        "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
        "\n",
        "La idea de este trabajo final es reproducir el siguiente paper:\n",
        "\n",
        "https://arxiv.org/pdf/1508.06576.pdf\n",
        "\n",
        "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
        "\n",
        "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
        "\n",
        "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
        "\n",
        "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
        "\n",
        "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
        "\n",
        "A este procedimiento se lo denomina neural style transfer.\n",
        "\n",
        "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
        "\n",
        "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
        "\n",
        "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyHsa2t0SxZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02bb7f45-2430-474e-c658-3c2b215b76dd"
      },
      "source": [
        "# Imagen para estilo\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
        "\n",
        "# Imagen para contenido\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
        "\n",
        "# Creamos el directorio para los archivos de salida\n",
        "!mkdir /content/output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-12 22:42:22--  https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.153.240, 2620:0:860:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.153.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 223725 (218K) [image/jpeg]\n",
            "Saving to: ‘La_noche_estrellada1.jpg.1’\n",
            "\n",
            "\r          La_noche_   0%[                    ]       0  --.-KB/s               \rLa_noche_estrellada 100%[===================>] 218.48K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-07-12 22:42:22 (2.54 MB/s) - ‘La_noche_estrellada1.jpg.1’ saved [223725/223725]\n",
            "\n",
            "--2022-07-12 22:42:22--  https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.153.240, 2620:0:860:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.153.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 153015 (149K) [image/jpeg]\n",
            "Saving to: ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.1’\n",
            "\n",
            "775px-Neckarfront_T 100%[===================>] 149.43K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-07-12 22:42:22 (2.02 MB/s) - ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.1’ saved [153015/153015]\n",
            "\n",
            "mkdir: cannot create directory ‘/content/output’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIxH20o2eFoc"
      },
      "source": [
        "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "import numpy as np\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import time\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K\n",
        "from pathlib import Path"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLkV1bnFl_tK"
      },
      "source": [
        "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
        "\n",
        "base_image_path = Path(\"/content/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
        "style_reference_image_path = Path(\"/content/La_noche_estrellada1.jpg\")\n",
        "result_prefix = Path(\"/content/output\")\n",
        "iterations = 100"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz2PeGfpeYzj"
      },
      "source": [
        "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
        "\n",
        "Respuesta: los parámetros mostrados a continuación se corresponden con las contribuciones (*weights*) de cada una de las losses (*content loss*, *style loss* y *total variation loss*) en la loss final a optimizar. En otras palabras, la loss es una suma ponderada de términos:\n",
        "\n",
        "\n",
        "*   *Content loss*: mide la distancia L2 entre los features maps de la imagen que aporta el contenido y la imagen combinada, generados por alguna de las últimas capas de la convnet. Se utilizan las activaciones de una capa profunda en la red ya que estas capturan aspectos generales y/o abstractos de la imagen.\n",
        "*  *Style loss*: mide cuan similares son en estilo la imagen generada y la imagen que aporta el estilo, para un conjunto de capas de activación a distintos niveles de profundidad de la convnet. El \"estilo\" es capturado a partir de la matriz de correlaciones (o matriz de Gram) de los features maps.\n",
        "*   *Totsl Variation loss*: funciona como regularización del modelo para evitar generar una imagen muy pixelada.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Dt3aaEmJWS"
      },
      "source": [
        "total_variation_weight = 0.1\n",
        "style_weight = 10\n",
        "content_weight = 1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQJOhCVuse6"
      },
      "source": [
        "# Definimos el tamaño de las imágenes a utilizar\n",
        "width, height = load_img(base_image_path).size\n",
        "img_nrows = 400\n",
        "img_ncols = int(width * img_nrows / height)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = load_img(base_image_path, target_size=(img_nrows, img_ncols))"
      ],
      "metadata": {
        "id": "WGZwISmgLMm0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = vgg19.preprocess_input(np.expand_dims(img, axis=0))"
      ],
      "metadata": {
        "id": "O7sDc6cgLUQ4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "ZHZ0I07mRs-d",
        "outputId": "d023a9e7-28e2-4be8-ef60-e5c48035a851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 400, 517, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = img.reshape((img_nrows, img_ncols, 3))"
      ],
      "metadata": {
        "id": "0cI7W7O3RvwC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img[:, :, ::-1].shape"
      ],
      "metadata": {
        "id": "6lvDv8rBR2zX",
        "outputId": "0f56038d-2929-4088-ab6c-5842805cb643",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 517, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[[1,2,3], [4,5,6]], [[7,8,9], [10,11,12]]])"
      ],
      "metadata": {
        "id": "aTTVu2I8SGo-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[:, :, ::-1]"
      ],
      "metadata": {
        "id": "XKP-nuPGSRtq",
        "outputId": "300277e5-c2ae-42ec-c9e1-630e997254da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 3,  2,  1],\n",
              "        [ 6,  5,  4]],\n",
              "\n",
              "       [[ 9,  8,  7],\n",
              "        [12, 11, 10]]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg2ct-8agm1E"
      },
      "source": [
        "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
        "\n",
        "Ayuda: https://keras.io/applications/\n",
        "\n",
        "Respuesta: la función tiene por parámetro al path de una imagen y preprocesará la misma de manera secuncial de la siguiente manera:\n",
        "\n",
        "\n",
        "1.   Carga la imagen en memoria a partir del path dado y ajusta su tamaño de acuerdo al tamaño definido en target_size.\n",
        "2.   Transforma la imagen de formato PIL a un array de tamaño 400 x 517 x 3 canales\n",
        "3.  Agrega una dimensión adicional al array la cual refiere al tamaño del batch: 1 batch_size x 400 x 517 x 3 canales. Este cambio de dimensiones busca adecuar el formato de la imagen al input esperado por la red de tipo VGG19.\n",
        "4.   Preprocesa/normaliza la imagen: primero convierte el formato de RGB a BGR y luego centra los valores de cada canal en 0 restándoles las medias de cada canal en base al dataset ImageNet, sin escalarlo.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAkljg4zuzYd"
      },
      "source": [
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return img"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTf0YDSagt10"
      },
      "source": [
        "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
        "\n",
        "Respuesta: esta función revierte el preprocesamiento hecho con la función anterior:\n",
        "\n",
        "1.   Transforma al tensor 4D en 3D, eliminando la dimension del batch_size\n",
        "2.   Revierte el centrado en 0 sumandole la media de cada canal de acuerdo al dataset ImageNet\n",
        "3.   Cambia el orden de los canales: en lugar de blue-green-red se pasa a red-green-blue\n",
        "4.   Garantiza que los valores se encuentre entre 0 y 255\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5LaTrsAu14z"
      },
      "source": [
        "def deprocess_image(x):\n",
        "    x = x.reshape((img_nrows, img_ncols, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.placeholder?"
      ],
      "metadata": {
        "id": "k8ssY6HATj02"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYNio09mu4S3"
      },
      "source": [
        "# get tensor representations of our images\n",
        "# K.variable convierte un numpy array en un tensor, para \n",
        "base_image = K.variable(preprocess_image(base_image_path))\n",
        "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Lbw02Uu--o"
      },
      "source": [
        "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJEi0YI3Uzrm"
      },
      "source": [
        "Aclaración:\n",
        "\n",
        "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGO_jGFfvEbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d699fb1-7875-424f-bdeb-7f6a45498abc"
      },
      "source": [
        "# combine the 3 images into a single Keras tensor\n",
        "input_tensor = K.concatenate([base_image,\n",
        "                              style_reference_image,\n",
        "                              combination_image], axis=0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.concat), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(1, 400, 517, 3) dtype=float32>\n",
            "  <tf.Variable 'Variable:0' shape=(1, 400, 517, 3) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdG59VRavHGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940388d0-3647-497d-d5c8-35f36fb969b5"
      },
      "source": [
        "# build the VGG19 network with our 3 images as input\n",
        "# the model will be loaded with pre-trained ImageNet weights\n",
        "model = vgg19.VGG19(input_tensor=input_tensor,\n",
        "                    weights='imagenet', include_top=False)\n",
        "print('Model loaded.')\n",
        "\n",
        "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_dict"
      ],
      "metadata": {
        "id": "zlcCy6kbUjo6",
        "outputId": "b2180f14-3c1b-41b3-fc78-6712fcb3843f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'block1_conv1': <KerasTensor: shape=(3, 400, 517, 64) dtype=float32 (created by layer 'block1_conv1')>,\n",
              " 'block1_conv2': <KerasTensor: shape=(3, 400, 517, 64) dtype=float32 (created by layer 'block1_conv2')>,\n",
              " 'block1_pool': <KerasTensor: shape=(3, 200, 258, 64) dtype=float32 (created by layer 'block1_pool')>,\n",
              " 'block2_conv1': <KerasTensor: shape=(3, 200, 258, 128) dtype=float32 (created by layer 'block2_conv1')>,\n",
              " 'block2_conv2': <KerasTensor: shape=(3, 200, 258, 128) dtype=float32 (created by layer 'block2_conv2')>,\n",
              " 'block2_pool': <KerasTensor: shape=(3, 100, 129, 128) dtype=float32 (created by layer 'block2_pool')>,\n",
              " 'block3_conv1': <KerasTensor: shape=(3, 100, 129, 256) dtype=float32 (created by layer 'block3_conv1')>,\n",
              " 'block3_conv2': <KerasTensor: shape=(3, 100, 129, 256) dtype=float32 (created by layer 'block3_conv2')>,\n",
              " 'block3_conv3': <KerasTensor: shape=(3, 100, 129, 256) dtype=float32 (created by layer 'block3_conv3')>,\n",
              " 'block3_conv4': <KerasTensor: shape=(3, 100, 129, 256) dtype=float32 (created by layer 'block3_conv4')>,\n",
              " 'block3_pool': <KerasTensor: shape=(3, 50, 64, 256) dtype=float32 (created by layer 'block3_pool')>,\n",
              " 'block4_conv1': <KerasTensor: shape=(3, 50, 64, 512) dtype=float32 (created by layer 'block4_conv1')>,\n",
              " 'block4_conv2': <KerasTensor: shape=(3, 50, 64, 512) dtype=float32 (created by layer 'block4_conv2')>,\n",
              " 'block4_conv3': <KerasTensor: shape=(3, 50, 64, 512) dtype=float32 (created by layer 'block4_conv3')>,\n",
              " 'block4_conv4': <KerasTensor: shape=(3, 50, 64, 512) dtype=float32 (created by layer 'block4_conv4')>,\n",
              " 'block4_pool': <KerasTensor: shape=(3, 25, 32, 512) dtype=float32 (created by layer 'block4_pool')>,\n",
              " 'block5_conv1': <KerasTensor: shape=(3, 25, 32, 512) dtype=float32 (created by layer 'block5_conv1')>,\n",
              " 'block5_conv2': <KerasTensor: shape=(3, 25, 32, 512) dtype=float32 (created by layer 'block5_conv2')>,\n",
              " 'block5_conv3': <KerasTensor: shape=(3, 25, 32, 512) dtype=float32 (created by layer 'block5_conv3')>,\n",
              " 'block5_conv4': <KerasTensor: shape=(3, 25, 32, 512) dtype=float32 (created by layer 'block5_conv4')>,\n",
              " 'block5_pool': <KerasTensor: shape=(3, 12, 16, 512) dtype=float32 (created by layer 'block5_pool')>,\n",
              " 'input_1': <KerasTensor: shape=(1, 400, 517, 3) dtype=float32 (created by layer 'input_1')>,\n",
              " 'tf.concat': <KerasTensor: shape=(3, 400, 517, 3) dtype=float32 (created by layer 'tf.concat')>}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70-vs_jZkKVc"
      },
      "source": [
        "# 4) En la siguientes celdas:\n",
        "\n",
        "- ¿Qué es la matriz de Gram?¿Para qué se usa?\n",
        "\n",
        "La matriz de Gram es una matriz simétrica de dimensión N, donde N es el número de feature maps o filtros para una capa específica de una convnet. Los elementos que la conforman son los productos punto de los feature_maps vectorizados (es decir, aplicando un flatten a cada feature map con dimensiones width x height x channels) y se asemejan a una correlación entre cada feature_map (sin centran ni promediar). Esta matriz captura el componente estilístico de la imagen: dado que cada feature_map se enfoca en una determinada característica de la imagen, un valor elevado del producto punto entre estos dos feature_maps indica que esas características suelen presentarse en conjunto en la imagen, frente a valores bajos que muestra que cierta combinación de patrones no esta presente en la imagen. Esta matriz se calcula para distitas layers, buscando capturar distintas texturas a diferentes escalas en lugar de la simple presencia o no de un objeto.\n",
        "\n",
        "- ¿Por qué se permutan las dimensiones de x?\n",
        "\n",
        "Las dimensiones del tensor se permutan antes de vectorizarlo para garantizar la conformidad de la matrices, esto es, para que puedan multiplicarse entre si. Esto permite que el producto punto entre filas y columnas se asimile a la correlación entre cada par de feature_maps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1FODPATvJ1k"
      },
      "source": [
        "def gram_matrix(x):\n",
        "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))\n",
        "    return gram"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQkKFY0Rbx-"
      },
      "source": [
        "# 5) Losses:\n",
        "\n",
        "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
        "\n",
        "Rta:\n",
        "\n",
        "* Content loss: mide la distancia L2 entre los features maps de la imagen que \n",
        "aporta el contenido y la imagen combinada, generados por alguna de las últimas capas de la convnet. Se utilizan las activaciones de una capa profunda en la red ya que estas capturan la presencia de aspectos más generales de la imagen.\n",
        "\n",
        "* Style loss: mide cuan similares son en estilo la imagen generada y la imagen que aporta el estilo, para un conjunto de capas de activación a distintos niveles de profundidad de la convnet. El \"estilo\" es capturado a partir de la matriz de correlaciones (o matriz de Gram) de los features maps.\n",
        "\n",
        "* Total Variation loss: funciona como regularización del modelo para evitar generar una imagen muy pixelada. La misma se basa en la distancia euclidea pixel a pixel entre dos \"recortes\" de la imagen con un pixel de diferencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Gt0ahWvN6q"
      },
      "source": [
        "def style_loss(style, combination):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCqnju5RvQCo"
      },
      "source": [
        "def content_loss(base, combination):\n",
        "    return K.sum(K.square(combination - base))\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udEp5h31vRnY"
      },
      "source": [
        "def total_variation_loss(x):\n",
        "    assert K.ndim(x) == 4\n",
        "    a = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
        "    b = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-65vcinbvTZ0"
      },
      "source": [
        "# Armamos la loss total\n",
        "loss = K.variable(0.0)\n",
        "layer_features = outputs_dict['block5_conv2']\n",
        "base_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[2, :, :, :]\n",
        "loss = loss + content_weight * content_loss(base_image_features,\n",
        "                                            combination_features)\n",
        "\n",
        "feature_layers = ['block1_conv1', 'block2_conv1',\n",
        "                  'block3_conv1', 'block4_conv1',\n",
        "                  'block5_conv1']\n",
        "for layer_name in feature_layers:\n",
        "    layer_features = outputs_dict[layer_name]\n",
        "    style_reference_features = layer_features[1, :, :, :] \n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    sl = style_loss(style_reference_features, combination_features)\n",
        "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
        "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "DXI-XhpQlctE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbz4n1OhvV2K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "4c86500c-6eed-405e-b9ae-d5ed82814f53"
      },
      "source": [
        "grads = K.gradients(loss, combination_image)\n",
        "\n",
        "outputs = [loss]\n",
        "if isinstance(grads, (list, tuple)):\n",
        "    outputs += grads\n",
        "else:\n",
        "    outputs.append(grads)\n",
        "\n",
        "f_outputs = K.function([combination_image], outputs)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-0244bd479fb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombination_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   4351\u001b[0m   \"\"\"\n\u001b[1;32m   4352\u001b[0m   return tf.compat.v1.gradients(\n\u001b[0;32m-> 4353\u001b[0;31m       loss, variables, colocate_gradients_with_ops=True)\n\u001b[0m\u001b[1;32m   4354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    169\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;31m# cluster ops for compilation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0mgradient_uid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_n_to_tensor_or_indexed_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m     xs = [\n\u001b[1;32m    517\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_resource_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py\u001b[0m in \u001b[0;36mconvert_n_to_tensor_or_indexed_slices\u001b[0;34m(values, dtype, name)\u001b[0m\n\u001b[1;32m    393\u001b[0m   \"\"\"\n\u001b[1;32m    394\u001b[0m   return internal_convert_n_to_tensor_or_indexed_slices(\n\u001b[0;32m--> 395\u001b[0;31m       values=values, dtype=dtype, name=name, as_ref=False)\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py\u001b[0m in \u001b[0;36minternal_convert_n_to_tensor_or_indexed_slices\u001b[0;34m(values, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    365\u001b[0m       ret.append(\n\u001b[1;32m    366\u001b[0m           internal_convert_to_tensor_or_indexed_slices(\n\u001b[0;32m--> 367\u001b[0;31m               value, dtype=dtype, name=n, as_ref=as_ref))\n\u001b[0m\u001b[1;32m    368\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor_or_indexed_slices\u001b[0;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    341\u001b[0m                                          as_ref=False):\n\u001b[1;32m    342\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m    267\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 268\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    284\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    285\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    287\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_is_array_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m   \u001b[0;31m# We first convert value to a numpy array or scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     raise TypeError(\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;34mf'You are passing {self}, an intermediate Keras symbolic input/output, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;34m'to a TF API that does not allow registering custom dispatchers, such '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;34m'as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='tf.__operators__.add_7/AddV2:0', description=\"created by layer 'tf.__operators__.add_7'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JbydbOaVcvU"
      },
      "source": [
        "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
        "\n",
        "Respuesta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVE1_qemvZeN"
      },
      "source": [
        "def eval_loss_and_grads(x):\n",
        "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "    outs = f_outputs([x])\n",
        "    loss_value = outs[0]\n",
        "    if len(outs[1:]) == 1:\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "    else:\n",
        "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "    return loss_value, grad_values\n",
        "\n",
        "# this Evaluator class makes it possible\n",
        "# to compute loss and gradients in one pass\n",
        "# while retrieving them via two separate functions,\n",
        "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
        "# requires separate functions for loss and gradients,\n",
        "# but computing them separately would be inefficient."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbl9roIgvdb1"
      },
      "source": [
        "class Evaluator(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb0yOEl-WOE6"
      },
      "source": [
        "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n31YBwCVvhAI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c1bf03c-9d66-48ea-93f2-4489fc20beaa"
      },
      "source": [
        "evaluator = Evaluator()\n",
        "\n",
        "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "# so as to minimize the neural style loss\n",
        "x = preprocess_image(base_image_path)\n",
        "\n",
        "for i in range(iterations):\n",
        "    print('Start of iteration', i)\n",
        "    start_time = time.time()\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
        "                                     fprime=evaluator.grads, maxfun=20)\n",
        "    print('Current loss value:', min_val)\n",
        "    # save current generated image\n",
        "    img = deprocess_image(x.copy())\n",
        "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
        "    save_img(fname, img)\n",
        "    end_time = time.time()\n",
        "    print('Image saved as', fname)\n",
        "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of iteration 0\n",
            "Current loss value: 13273409000.0\n",
            "Image saved as /content/output/output_at_iteration_0.png\n",
            "Iteration 0 completed in 11s\n",
            "Start of iteration 1\n",
            "Current loss value: 6347451000.0\n",
            "Image saved as /content/output/output_at_iteration_1.png\n",
            "Iteration 1 completed in 4s\n",
            "Start of iteration 2\n",
            "Current loss value: 4452764000.0\n",
            "Image saved as /content/output/output_at_iteration_2.png\n",
            "Iteration 2 completed in 4s\n",
            "Start of iteration 3\n",
            "Current loss value: 3511758300.0\n",
            "Image saved as /content/output/output_at_iteration_3.png\n",
            "Iteration 3 completed in 4s\n",
            "Start of iteration 4\n",
            "Current loss value: 2822316000.0\n",
            "Image saved as /content/output/output_at_iteration_4.png\n",
            "Iteration 4 completed in 4s\n",
            "Start of iteration 5\n",
            "Current loss value: 2412456400.0\n",
            "Image saved as /content/output/output_at_iteration_5.png\n",
            "Iteration 5 completed in 4s\n",
            "Start of iteration 6\n",
            "Current loss value: 2135097300.0\n",
            "Image saved as /content/output/output_at_iteration_6.png\n",
            "Iteration 6 completed in 4s\n",
            "Start of iteration 7\n",
            "Current loss value: 1970264800.0\n",
            "Image saved as /content/output/output_at_iteration_7.png\n",
            "Iteration 7 completed in 4s\n",
            "Start of iteration 8\n",
            "Current loss value: 1860384800.0\n",
            "Image saved as /content/output/output_at_iteration_8.png\n",
            "Iteration 8 completed in 4s\n",
            "Start of iteration 9\n",
            "Current loss value: 1751609500.0\n",
            "Image saved as /content/output/output_at_iteration_9.png\n",
            "Iteration 9 completed in 4s\n",
            "Start of iteration 10\n",
            "Current loss value: 1669193200.0\n",
            "Image saved as /content/output/output_at_iteration_10.png\n",
            "Iteration 10 completed in 4s\n",
            "Start of iteration 11\n",
            "Current loss value: 1578533200.0\n",
            "Image saved as /content/output/output_at_iteration_11.png\n",
            "Iteration 11 completed in 4s\n",
            "Start of iteration 12\n",
            "Current loss value: 1517204700.0\n",
            "Image saved as /content/output/output_at_iteration_12.png\n",
            "Iteration 12 completed in 4s\n",
            "Start of iteration 13\n",
            "Current loss value: 1467499100.0\n",
            "Image saved as /content/output/output_at_iteration_13.png\n",
            "Iteration 13 completed in 4s\n",
            "Start of iteration 14\n",
            "Current loss value: 1425280800.0\n",
            "Image saved as /content/output/output_at_iteration_14.png\n",
            "Iteration 14 completed in 4s\n",
            "Start of iteration 15\n",
            "Current loss value: 1391144700.0\n",
            "Image saved as /content/output/output_at_iteration_15.png\n",
            "Iteration 15 completed in 4s\n",
            "Start of iteration 16\n",
            "Current loss value: 1354899500.0\n",
            "Image saved as /content/output/output_at_iteration_16.png\n",
            "Iteration 16 completed in 4s\n",
            "Start of iteration 17\n",
            "Current loss value: 1326892500.0\n",
            "Image saved as /content/output/output_at_iteration_17.png\n",
            "Iteration 17 completed in 4s\n",
            "Start of iteration 18\n",
            "Current loss value: 1303227000.0\n",
            "Image saved as /content/output/output_at_iteration_18.png\n",
            "Iteration 18 completed in 4s\n",
            "Start of iteration 19\n",
            "Current loss value: 1269311400.0\n",
            "Image saved as /content/output/output_at_iteration_19.png\n",
            "Iteration 19 completed in 4s\n",
            "Start of iteration 20\n",
            "Current loss value: 1246992000.0\n",
            "Image saved as /content/output/output_at_iteration_20.png\n",
            "Iteration 20 completed in 4s\n",
            "Start of iteration 21\n",
            "Current loss value: 1229419000.0\n",
            "Image saved as /content/output/output_at_iteration_21.png\n",
            "Iteration 21 completed in 4s\n",
            "Start of iteration 22\n",
            "Current loss value: 1214691000.0\n",
            "Image saved as /content/output/output_at_iteration_22.png\n",
            "Iteration 22 completed in 4s\n",
            "Start of iteration 23\n",
            "Current loss value: 1202314500.0\n",
            "Image saved as /content/output/output_at_iteration_23.png\n",
            "Iteration 23 completed in 4s\n",
            "Start of iteration 24\n",
            "Current loss value: 1191065700.0\n",
            "Image saved as /content/output/output_at_iteration_24.png\n",
            "Iteration 24 completed in 4s\n",
            "Start of iteration 25\n",
            "Current loss value: 1180488200.0\n",
            "Image saved as /content/output/output_at_iteration_25.png\n",
            "Iteration 25 completed in 4s\n",
            "Start of iteration 26\n",
            "Current loss value: 1170969700.0\n",
            "Image saved as /content/output/output_at_iteration_26.png\n",
            "Iteration 26 completed in 4s\n",
            "Start of iteration 27\n",
            "Current loss value: 1155740700.0\n",
            "Image saved as /content/output/output_at_iteration_27.png\n",
            "Iteration 27 completed in 4s\n",
            "Start of iteration 28\n",
            "Current loss value: 1142597900.0\n",
            "Image saved as /content/output/output_at_iteration_28.png\n",
            "Iteration 28 completed in 4s\n",
            "Start of iteration 29\n",
            "Current loss value: 1132743800.0\n",
            "Image saved as /content/output/output_at_iteration_29.png\n",
            "Iteration 29 completed in 4s\n",
            "Start of iteration 30\n",
            "Current loss value: 1124286000.0\n",
            "Image saved as /content/output/output_at_iteration_30.png\n",
            "Iteration 30 completed in 4s\n",
            "Start of iteration 31\n",
            "Current loss value: 1115296400.0\n",
            "Image saved as /content/output/output_at_iteration_31.png\n",
            "Iteration 31 completed in 4s\n",
            "Start of iteration 32\n",
            "Current loss value: 1107436300.0\n",
            "Image saved as /content/output/output_at_iteration_32.png\n",
            "Iteration 32 completed in 4s\n",
            "Start of iteration 33\n",
            "Current loss value: 1096296700.0\n",
            "Image saved as /content/output/output_at_iteration_33.png\n",
            "Iteration 33 completed in 4s\n",
            "Start of iteration 34\n",
            "Current loss value: 1087182000.0\n",
            "Image saved as /content/output/output_at_iteration_34.png\n",
            "Iteration 34 completed in 4s\n",
            "Start of iteration 35\n",
            "Current loss value: 1075933600.0\n",
            "Image saved as /content/output/output_at_iteration_35.png\n",
            "Iteration 35 completed in 4s\n",
            "Start of iteration 36\n",
            "Current loss value: 1066292300.0\n",
            "Image saved as /content/output/output_at_iteration_36.png\n",
            "Iteration 36 completed in 4s\n",
            "Start of iteration 37\n",
            "Current loss value: 1061817860.0\n",
            "Image saved as /content/output/output_at_iteration_37.png\n",
            "Iteration 37 completed in 4s\n",
            "Start of iteration 38\n",
            "Current loss value: 1057405300.0\n",
            "Image saved as /content/output/output_at_iteration_38.png\n",
            "Iteration 38 completed in 4s\n",
            "Start of iteration 39\n",
            "Current loss value: 1052422700.0\n",
            "Image saved as /content/output/output_at_iteration_39.png\n",
            "Iteration 39 completed in 4s\n",
            "Start of iteration 40\n",
            "Current loss value: 1046551300.0\n",
            "Image saved as /content/output/output_at_iteration_40.png\n",
            "Iteration 40 completed in 4s\n",
            "Start of iteration 41\n",
            "Current loss value: 1040783550.0\n",
            "Image saved as /content/output/output_at_iteration_41.png\n",
            "Iteration 41 completed in 4s\n",
            "Start of iteration 42\n",
            "Current loss value: 1035612400.0\n",
            "Image saved as /content/output/output_at_iteration_42.png\n",
            "Iteration 42 completed in 4s\n",
            "Start of iteration 43\n",
            "Current loss value: 1031173950.0\n",
            "Image saved as /content/output/output_at_iteration_43.png\n",
            "Iteration 43 completed in 4s\n",
            "Start of iteration 44\n",
            "Current loss value: 1026627900.0\n",
            "Image saved as /content/output/output_at_iteration_44.png\n",
            "Iteration 44 completed in 4s\n",
            "Start of iteration 45\n",
            "Current loss value: 1022867460.0\n",
            "Image saved as /content/output/output_at_iteration_45.png\n",
            "Iteration 45 completed in 4s\n",
            "Start of iteration 46\n",
            "Current loss value: 1019472700.0\n",
            "Image saved as /content/output/output_at_iteration_46.png\n",
            "Iteration 46 completed in 4s\n",
            "Start of iteration 47\n",
            "Current loss value: 1016219500.0\n",
            "Image saved as /content/output/output_at_iteration_47.png\n",
            "Iteration 47 completed in 4s\n",
            "Start of iteration 48\n",
            "Current loss value: 1013103740.0\n",
            "Image saved as /content/output/output_at_iteration_48.png\n",
            "Iteration 48 completed in 4s\n",
            "Start of iteration 49\n",
            "Current loss value: 1010084860.0\n",
            "Image saved as /content/output/output_at_iteration_49.png\n",
            "Iteration 49 completed in 4s\n",
            "Start of iteration 50\n",
            "Current loss value: 1007337600.0\n",
            "Image saved as /content/output/output_at_iteration_50.png\n",
            "Iteration 50 completed in 4s\n",
            "Start of iteration 51\n",
            "Current loss value: 1002772200.0\n",
            "Image saved as /content/output/output_at_iteration_51.png\n",
            "Iteration 51 completed in 4s\n",
            "Start of iteration 52\n",
            "Current loss value: 998898300.0\n",
            "Image saved as /content/output/output_at_iteration_52.png\n",
            "Iteration 52 completed in 4s\n",
            "Start of iteration 53\n",
            "Current loss value: 995866700.0\n",
            "Image saved as /content/output/output_at_iteration_53.png\n",
            "Iteration 53 completed in 4s\n",
            "Start of iteration 54\n",
            "Current loss value: 992903700.0\n",
            "Image saved as /content/output/output_at_iteration_54.png\n",
            "Iteration 54 completed in 4s\n",
            "Start of iteration 55\n",
            "Current loss value: 990754560.0\n",
            "Image saved as /content/output/output_at_iteration_55.png\n",
            "Iteration 55 completed in 4s\n",
            "Start of iteration 56\n",
            "Current loss value: 988550800.0\n",
            "Image saved as /content/output/output_at_iteration_56.png\n",
            "Iteration 56 completed in 4s\n",
            "Start of iteration 57\n",
            "Current loss value: 986259300.0\n",
            "Image saved as /content/output/output_at_iteration_57.png\n",
            "Iteration 57 completed in 4s\n",
            "Start of iteration 58\n",
            "Current loss value: 984072260.0\n",
            "Image saved as /content/output/output_at_iteration_58.png\n",
            "Iteration 58 completed in 4s\n",
            "Start of iteration 59\n",
            "Current loss value: 981666300.0\n",
            "Image saved as /content/output/output_at_iteration_59.png\n",
            "Iteration 59 completed in 4s\n",
            "Start of iteration 60\n",
            "Current loss value: 979823800.0\n",
            "Image saved as /content/output/output_at_iteration_60.png\n",
            "Iteration 60 completed in 4s\n",
            "Start of iteration 61\n",
            "Current loss value: 977143550.0\n",
            "Image saved as /content/output/output_at_iteration_61.png\n",
            "Iteration 61 completed in 4s\n",
            "Start of iteration 62\n",
            "Current loss value: 974104960.0\n",
            "Image saved as /content/output/output_at_iteration_62.png\n",
            "Iteration 62 completed in 4s\n",
            "Start of iteration 63\n",
            "Current loss value: 972086300.0\n",
            "Image saved as /content/output/output_at_iteration_63.png\n",
            "Iteration 63 completed in 4s\n",
            "Start of iteration 64\n",
            "Current loss value: 969961500.0\n",
            "Image saved as /content/output/output_at_iteration_64.png\n",
            "Iteration 64 completed in 4s\n",
            "Start of iteration 65\n",
            "Current loss value: 967741700.0\n",
            "Image saved as /content/output/output_at_iteration_65.png\n",
            "Iteration 65 completed in 4s\n",
            "Start of iteration 66\n",
            "Current loss value: 965645060.0\n",
            "Image saved as /content/output/output_at_iteration_66.png\n",
            "Iteration 66 completed in 4s\n",
            "Start of iteration 67\n",
            "Current loss value: 964051200.0\n",
            "Image saved as /content/output/output_at_iteration_67.png\n",
            "Iteration 67 completed in 4s\n",
            "Start of iteration 68\n",
            "Current loss value: 962240260.0\n",
            "Image saved as /content/output/output_at_iteration_68.png\n",
            "Iteration 68 completed in 4s\n",
            "Start of iteration 69\n",
            "Current loss value: 960589800.0\n",
            "Image saved as /content/output/output_at_iteration_69.png\n",
            "Iteration 69 completed in 4s\n",
            "Start of iteration 70\n",
            "Current loss value: 958313340.0\n",
            "Image saved as /content/output/output_at_iteration_70.png\n",
            "Iteration 70 completed in 4s\n",
            "Start of iteration 71\n",
            "Current loss value: 955996600.0\n",
            "Image saved as /content/output/output_at_iteration_71.png\n",
            "Iteration 71 completed in 4s\n",
            "Start of iteration 72\n",
            "Current loss value: 953897340.0\n",
            "Image saved as /content/output/output_at_iteration_72.png\n",
            "Iteration 72 completed in 4s\n",
            "Start of iteration 73\n",
            "Current loss value: 951580000.0\n",
            "Image saved as /content/output/output_at_iteration_73.png\n",
            "Iteration 73 completed in 4s\n",
            "Start of iteration 74\n",
            "Current loss value: 949822340.0\n",
            "Image saved as /content/output/output_at_iteration_74.png\n",
            "Iteration 74 completed in 4s\n",
            "Start of iteration 75\n",
            "Current loss value: 948128900.0\n",
            "Image saved as /content/output/output_at_iteration_75.png\n",
            "Iteration 75 completed in 4s\n",
            "Start of iteration 76\n",
            "Current loss value: 946001900.0\n",
            "Image saved as /content/output/output_at_iteration_76.png\n",
            "Iteration 76 completed in 4s\n",
            "Start of iteration 77\n",
            "Current loss value: 943861900.0\n",
            "Image saved as /content/output/output_at_iteration_77.png\n",
            "Iteration 77 completed in 4s\n",
            "Start of iteration 78\n",
            "Current loss value: 942313340.0\n",
            "Image saved as /content/output/output_at_iteration_78.png\n",
            "Iteration 78 completed in 4s\n",
            "Start of iteration 79\n",
            "Current loss value: 940783360.0\n",
            "Image saved as /content/output/output_at_iteration_79.png\n",
            "Iteration 79 completed in 4s\n",
            "Start of iteration 80\n",
            "Current loss value: 939503300.0\n",
            "Image saved as /content/output/output_at_iteration_80.png\n",
            "Iteration 80 completed in 4s\n",
            "Start of iteration 81\n",
            "Current loss value: 938181500.0\n",
            "Image saved as /content/output/output_at_iteration_81.png\n",
            "Iteration 81 completed in 4s\n",
            "Start of iteration 82\n",
            "Current loss value: 936953340.0\n",
            "Image saved as /content/output/output_at_iteration_82.png\n",
            "Iteration 82 completed in 4s\n",
            "Start of iteration 83\n",
            "Current loss value: 935529150.0\n",
            "Image saved as /content/output/output_at_iteration_83.png\n",
            "Iteration 83 completed in 4s\n",
            "Start of iteration 84\n",
            "Current loss value: 934318460.0\n",
            "Image saved as /content/output/output_at_iteration_84.png\n",
            "Iteration 84 completed in 4s\n",
            "Start of iteration 85\n",
            "Current loss value: 933139400.0\n",
            "Image saved as /content/output/output_at_iteration_85.png\n",
            "Iteration 85 completed in 4s\n",
            "Start of iteration 86\n",
            "Current loss value: 931855000.0\n",
            "Image saved as /content/output/output_at_iteration_86.png\n",
            "Iteration 86 completed in 4s\n",
            "Start of iteration 87\n",
            "Current loss value: 930877440.0\n",
            "Image saved as /content/output/output_at_iteration_87.png\n",
            "Iteration 87 completed in 4s\n",
            "Start of iteration 88\n",
            "Current loss value: 929110600.0\n",
            "Image saved as /content/output/output_at_iteration_88.png\n",
            "Iteration 88 completed in 4s\n",
            "Start of iteration 89\n",
            "Current loss value: 927320400.0\n",
            "Image saved as /content/output/output_at_iteration_89.png\n",
            "Iteration 89 completed in 4s\n",
            "Start of iteration 90\n",
            "Current loss value: 925080770.0\n",
            "Image saved as /content/output/output_at_iteration_90.png\n",
            "Iteration 90 completed in 4s\n",
            "Start of iteration 91\n",
            "Current loss value: 922863360.0\n",
            "Image saved as /content/output/output_at_iteration_91.png\n",
            "Iteration 91 completed in 4s\n",
            "Start of iteration 92\n",
            "Current loss value: 921263500.0\n",
            "Image saved as /content/output/output_at_iteration_92.png\n",
            "Iteration 92 completed in 4s\n",
            "Start of iteration 93\n",
            "Current loss value: 919812350.0\n",
            "Image saved as /content/output/output_at_iteration_93.png\n",
            "Iteration 93 completed in 4s\n",
            "Start of iteration 94\n",
            "Current loss value: 918680450.0\n",
            "Image saved as /content/output/output_at_iteration_94.png\n",
            "Iteration 94 completed in 4s\n",
            "Start of iteration 95\n",
            "Current loss value: 917604540.0\n",
            "Image saved as /content/output/output_at_iteration_95.png\n",
            "Iteration 95 completed in 4s\n",
            "Start of iteration 96\n",
            "Current loss value: 916276500.0\n",
            "Image saved as /content/output/output_at_iteration_96.png\n",
            "Iteration 96 completed in 4s\n",
            "Start of iteration 97\n",
            "Current loss value: 915087500.0\n",
            "Image saved as /content/output/output_at_iteration_97.png\n",
            "Iteration 97 completed in 4s\n",
            "Start of iteration 98\n",
            "Current loss value: 914183300.0\n",
            "Image saved as /content/output/output_at_iteration_98.png\n",
            "Iteration 98 completed in 4s\n",
            "Start of iteration 99\n",
            "Current loss value: 913010800.0\n",
            "Image saved as /content/output/output_at_iteration_99.png\n",
            "Iteration 99 completed in 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkiJtofbWWy1"
      },
      "source": [
        "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
        "\n",
        "Respuesta:\n",
        "\n",
        "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
        "\n",
        "Respuesta:"
      ]
    }
  ]
}